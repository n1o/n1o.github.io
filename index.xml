<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data, Code and Breaking Stuff</title><link>https://n1o.github.io/</link><description>Recent content on Data, Code and Breaking Stuff</description><generator>Hugo</generator><language>en</language><lastBuildDate>Wed, 06 Mar 2024 12:58:32 +0100</lastBuildDate><atom:link href="https://n1o.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>T5 the Old New Thing</title><link>https://n1o.github.io/posts/t5-the-old-new-thing/</link><pubDate>Wed, 06 Mar 2024 12:58:32 +0100</pubDate><guid>https://n1o.github.io/posts/t5-the-old-new-thing/</guid><description>Why T5 Link to heading A couple of weeks ago I run into the following paper Tiny Titans. It compares multiple smallish (up to 1B parameters) open source LLMs with bigger proprietary ones on meeting summarization. TLDR; the small models tend to perform worse in zero-shot setting as well after fine-tunnig than big ones. Except for FLAN-T5-Large which after finetuning performs way beyond its league, beating even the biggest proprietary models (GPT-3.</description></item><item><title>Nixos for Hobby Project</title><link>https://n1o.github.io/posts/nixos-for-hobby-project/</link><pubDate>Wed, 13 Sep 2023 13:09:10 +0200</pubDate><guid>https://n1o.github.io/posts/nixos-for-hobby-project/</guid><description>Lately, I&amp;rsquo;ve embarked on a side project: CodeBreakers. It&amp;rsquo;s nothing too fancy, just a website where I plan to release videos and articles about my latest passionsâ€”Reverse Engineering and Binary Exploitation.
Creating a website isn&amp;rsquo;t all that complex, and I&amp;rsquo;ve done it a couple of times before. The main challenge was deciding where and how to host it. Initially, I considered using Fly ((which is a fantastic PaaS product with many built-in features), but ultimately, I opted for Hetzner and rented a virtual server.</description></item><item><title>Paper overview: Hungry Hungry Hippos: Towards Language Modeling with State Space Models</title><link>https://n1o.github.io/posts/hungry-hungry-hippos/</link><pubDate>Mon, 06 Feb 2023 09:39:03 +0100</pubDate><guid>https://n1o.github.io/posts/hungry-hungry-hippos/</guid><description>High level overview Link to heading By combining State Space Models (SSMs) with Attention, we get a model that generates text more efficiently, with a speed increase of approximately 1.6 times. Additionally, this approach requires less paremters, enabling the development of larger models on existing hardware.
Language modeling requirements Link to heading The Transformer architecture, which forms the basis of ChatGPT, is riding high on the hype train due to its impressive performance.</description></item><item><title>Paper overview: Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations</title><link>https://n1o.github.io/posts/continuous-time-modeling-of-counterfatual-outcomes/</link><pubDate>Mon, 16 Jan 2023 17:37:36 +0100</pubDate><guid>https://n1o.github.io/posts/continuous-time-modeling-of-counterfatual-outcomes/</guid><description>The problem it solves Link to heading Imagine you have an irregullary sampled time series, where at various time points we perform interventions. These interventions may influence the dynamics of the timeseries. The question we want to answer is:
If I perform a hypothetical sequence of interventions how will my time series evolve?
An example and some details Link to heading Example Link to heading As a medical doctor in a hospital, if a patient has a high fever and is at risk of dying, a common practice is to measure their levels of C-reactive protein (CRP) to determine if they need antibiotics.</description></item><item><title>Hierarchical Probabilistic Matrix Factorization</title><link>https://n1o.github.io/posts/pooled_matrix_factorization/</link><pubDate>Thu, 17 Dec 2020 10:19:42 +0100</pubDate><guid>https://n1o.github.io/posts/pooled_matrix_factorization/</guid><description>Probabilistic Matrix factorization is a simple but useful model for matrix imputation. The main idea is to decompose a tall and wide matrix into a product of two matrices, one tall and thin and one short and wide.
$$ R_{n\times m} = U_{m \times d} \cdot V_{d \times n} $$
If you are a Bayesian, you can express this model as:
$$ R_{ij} \sim \mathcal{N}(u_i \cdot v_j^T, \sigma) $$ $$ u_i \sim \mathcal{N}(\mu_u, \Sigma_u) $$ $$ v_j \sim \mathcal{N}(\mu_v, \Sigma_v) $$</description></item><item><title/><link>https://n1o.github.io/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://n1o.github.io/about/</guid><description>About Link to heading I&amp;rsquo;m Marek Barak, I started my journey into computer science when I was 15 by coding in C++, without having access to the internet and in good old fashioned Bloodshed C++ Since then more than 15 years has passed, and I managed to get an Master degree in computer science and statistics from the University of Economics in Bratislava. I had to opportunity to do build machine learning and distributed systems for early to mid sage startups.</description></item><item><title/><link>https://n1o.github.io/contact/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://n1o.github.io/contact/</guid><description>Contact Link to heading Feel free to contact me via email mrk.barak@gmail.com or socials.</description></item><item><title/><link>https://n1o.github.io/projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://n1o.github.io/projects/</guid><description>Projects Link to heading Study notes Link to heading This is my compilation of notes from various subjects. This is work in progress, where I continuously migrate, rewrite, simplify the notes I have. During the years I wrote thousands of pages worth of notes, not always concise. Right now I prefer taking notes that are somewhat similar to the Zettelkasten method. Thus keeping them short, easy to follow, covering at most a single subject.</description></item></channel></rss>