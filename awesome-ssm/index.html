<!doctype html><html lang=en><head><title>Awesome SSM Â· Data, Code and Breaking Stuff
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="n1o_c0rTx"><meta name=description content="This series will cover a bunch of posts about State Space Models, their extensions and applications.

  Basics
  
    
    Link to heading
  


Mamba, Mamba2


  Bidirectional
  
    
    Link to heading
  


Hydra


  Attention Hybrids
  
    
    Link to heading
  


SSM-Transformer Hybrids covers:

An Empirical Study of Mamba-based Language Models
SAMBA Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling
Jamba A Hybrid Transformer-Mamba Language Model
Jamba 1.5 Hybrid Transformer-Mamba Models at Scale
Zamba A Compact 7B SSM Hybrid Model
Zamba2-small
Zamba2-mini




  Theory and Limitations
  
    
    Link to heading
  


Illusion of State in SSMs like Mamba covers:

The Expressive Capacity of State Space Models: A Formal Language Perspective
The Illusion of State in State-Space Models




  With Graphs
  
    
    Link to heading
  


Graph Mamba: Towards Learning on Graphs with State Space Models

we leverage SSMs an alternative to Message Passing in Graph Neural Networks




  Distillation
  
    
    Link to heading
  


Transformers to SSMs: Distilling Quadratic Knowledge to Subquadratic Models

idea is to take an pretrained transformer and distill it into a SSM




  Reinforcement Learning
  
    
    Link to heading
  


Decision Mamba: Reinforcement Learning via Sequence Modeling with Selective State Spaces

apply SSMs to Sequential Decision Making


"><meta name=keywords content="blog,developer,personal"><meta name=fediverse:creator content><meta name=twitter:card content="summary"><meta name=twitter:title content="Awesome SSM"><meta name=twitter:description content="This series will cover a bunch of posts about State Space Models, their extensions and applications.
Basics Link to heading Mamba, Mamba2 Bidirectional Link to heading Hydra Attention Hybrids Link to heading SSM-Transformer Hybrids covers: An Empirical Study of Mamba-based Language Models SAMBA Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling Jamba A Hybrid Transformer-Mamba Language Model Jamba 1.5 Hybrid Transformer-Mamba Models at Scale Zamba A Compact 7B SSM Hybrid Model Zamba2-small Zamba2-mini Theory and Limitations Link to heading Illusion of State in SSMs like Mamba covers: The Expressive Capacity of State Space Models: A Formal Language Perspective The Illusion of State in State-Space Models With Graphs Link to heading Graph Mamba: Towards Learning on Graphs with State Space Models we leverage SSMs an alternative to Message Passing in Graph Neural Networks Distillation Link to heading Transformers to SSMs: Distilling Quadratic Knowledge to Subquadratic Models idea is to take an pretrained transformer and distill it into a SSM Reinforcement Learning Link to heading Decision Mamba: Reinforcement Learning via Sequence Modeling with Selective State Spaces apply SSMs to Sequential Decision Making "><meta property="og:url" content="https://n1o.github.io/awesome-ssm/"><meta property="og:site_name" content="Data, Code and Breaking Stuff"><meta property="og:title" content="Awesome SSM"><meta property="og:description" content="This series will cover a bunch of posts about State Space Models, their extensions and applications.
Basics Link to heading Mamba, Mamba2 Bidirectional Link to heading Hydra Attention Hybrids Link to heading SSM-Transformer Hybrids covers: An Empirical Study of Mamba-based Language Models SAMBA Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling Jamba A Hybrid Transformer-Mamba Language Model Jamba 1.5 Hybrid Transformer-Mamba Models at Scale Zamba A Compact 7B SSM Hybrid Model Zamba2-small Zamba2-mini Theory and Limitations Link to heading Illusion of State in SSMs like Mamba covers: The Expressive Capacity of State Space Models: A Formal Language Perspective The Illusion of State in State-Space Models With Graphs Link to heading Graph Mamba: Towards Learning on Graphs with State Space Models we leverage SSMs an alternative to Message Passing in Graph Neural Networks Distillation Link to heading Transformers to SSMs: Distilling Quadratic Knowledge to Subquadratic Models idea is to take an pretrained transformer and distill it into a SSM Reinforcement Learning Link to heading Decision Mamba: Reinforcement Learning via Sequence Modeling with Selective State Spaces apply SSMs to Sequential Decision Making "><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:published_time" content="2024-09-05T10:39:29+01:00"><meta property="article:modified_time" content="2024-09-05T10:39:29+01:00"><link rel=canonical href=https://n1o.github.io/awesome-ssm/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.e927f7340e309d76dcb8fda85f1531ae7341aa9cd0b7f3ab77885dae77b1a0a2.css integrity="sha256-6Sf3NA4wnXbcuP2oXxUxrnNBqpzQt/Ord4hdrnexoKI=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://n1o.github.io/>Data, Code and Breaking Stuff
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/about/>About</a></li><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=/awesome-t5/>Awesome T5</a></li><li class=navigation-item><a class=navigation-link href=/awesome-ssm/>Awesome SSM</a></li><li class=navigation-item><a class=navigation-link href=/projects/>Projects</a></li><li class=navigation-item><a class=navigation-link href=/contact/>Contact me</a></li></ul></section></nav><div class=content><section class="container page"><article><header><h1 class=title><a class=title-link href=https://n1o.github.io/awesome-ssm/>Awesome SSM</a></h1></header><p>This series will cover a bunch of posts about State Space Models, their extensions and applications.</p><h1 id=basics>Basics
<a class=heading-link href=#basics><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><ul><li><a href=/posts/from-mamba-to-mamba2/>Mamba, Mamba2</a></li></ul><h1 id=bidirectional>Bidirectional
<a class=heading-link href=#bidirectional><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><ul><li><a href=/posts/hydra-a-double-headed-mamba/>Hydra</a></li></ul><h1 id=attention-hybrids>Attention Hybrids
<a class=heading-link href=#attention-hybrids><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><ul><li><a href=/posts/ssm-transformer-hybrids-guide/>SSM-Transformer Hybrids</a> covers:<ul><li><a href=https://arxiv.org/abs/2406.07887 class=external-link target=_blank rel=noopener>An Empirical Study of Mamba-based Language Models</a></li><li><a href=https://arxiv.org/html/2406.07522v1 class=external-link target=_blank rel=noopener>SAMBA Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling</a></li><li><a href=https://arxiv.org/abs/2403.19887v1 class=external-link target=_blank rel=noopener>Jamba A Hybrid Transformer-Mamba Language Model</a></li><li><a href=https://arxiv.org/abs/2408.12570 class=external-link target=_blank rel=noopener>Jamba 1.5 Hybrid Transformer-Mamba Models at Scale</a></li><li><a href=https://arxiv.org/abs/2405.16712v1 class=external-link target=_blank rel=noopener>Zamba A Compact 7B SSM Hybrid Model</a></li><li><a href=https://www.zyphra.com/post/zamba2-small class=external-link target=_blank rel=noopener>Zamba2-small</a></li><li><a href=https://www.zyphra.com/post/zamba2-mini class=external-link target=_blank rel=noopener>Zamba2-mini</a></li></ul></li></ul><h1 id=theory-and-limitations>Theory and Limitations
<a class=heading-link href=#theory-and-limitations><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><ul><li><a href=/posts/ssm-the-illusion/>Illusion of State in SSMs like Mamba</a> covers:<ul><li><a href=https://www.semanticscholar.org/paper/The-Expressive-Capacity-of-State-Space-Models%3A-A-Sarrof-Veitsman/e7f47e8393c697696a3fccd9ff906dfdb49fe736 class=external-link target=_blank rel=noopener>The Expressive Capacity of State Space Models: A Formal Language Perspective</a></li><li><a href=https://www.semanticscholar.org/paper/The-Illusion-of-State-in-State-Space-Models-Merrill-Petty/917479a7a72ee7c1fb320c14d770e30ef322ef28 class=external-link target=_blank rel=noopener>The Illusion of State in State-Space Models</a></li></ul></li></ul><h1 id=with-graphs>With Graphs
<a class=heading-link href=#with-graphs><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><ul><li><a href=https://www.semanticscholar.org/paper/Graph-Mamba%3A-Towards-Learning-on-Graphs-with-State-Behrouz-Hashemi/2dda6da7375bf5e8bcf60f87b17ba10757f3bc57 class=external-link target=_blank rel=noopener>Graph Mamba: Towards Learning on Graphs with State Space Models</a><ul><li>we leverage SSMs an alternative to Message Passing in Graph Neural Networks</li></ul></li></ul><h1 id=distillation>Distillation
<a class=heading-link href=#distillation><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><ul><li><a href=https://browse.arxiv.org/abs/2408.10189v1 class=external-link target=_blank rel=noopener>Transformers to SSMs: Distilling Quadratic Knowledge to Subquadratic Models</a><ul><li>idea is to take an pretrained transformer and distill it into a SSM</li></ul></li></ul><h1 id=reinforcement-learning>Reinforcement Learning
<a class=heading-link href=#reinforcement-learning><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><ul><li><a href=https://www.semanticscholar.org/paper/Decision-Mamba%3A-Reinforcement-Learning-via-Sequence-Ota/9b8130a2a5d3398f4993f540ddd01d440d99d62e class=external-link target=_blank rel=noopener>Decision Mamba: Reinforcement Learning via Sequence Modeling with Selective State Spaces</a><ul><li>apply SSMs to Sequential Decision Making</li></ul></li></ul></article></section><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></div><footer class=footer><section class=container>Â©
2020 -
2024
n1o_c0rTx
Â·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-5WLCXX3LGJ"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-5WLCXX3LGJ")}</script></body></html>